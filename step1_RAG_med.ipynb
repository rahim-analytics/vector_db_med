{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a500a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Science & AI\\Medical Chatbot Using RAG\\vector_db_med\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e01a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "def load_pdf_files(data):\n",
    "    Loader = DirectoryLoader(data, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = Loader.load()\n",
    "    return documents\n",
    "documents = load_pdf_files(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16bbbf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of the documents: 759\n"
     ]
    }
   ],
   "source": [
    "print(\"lenght of the documents:\",len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93554f4",
   "metadata": {},
   "source": [
    "Creating Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ae72d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 7080\n"
     ]
    }
   ],
   "source": [
    "def create_chunks(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len\n",
    "    )\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "chunks = create_chunks(documents)\n",
    "print(\"Number of chunks:\", len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb602c41",
   "metadata": {},
   "source": [
    "Create Vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfbf123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahim\\AppData\\Local\\Temp\\ipykernel_8492\\1823034447.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name= \"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created\n"
     ]
    }
   ],
   "source": [
    "def create_embeddings(chunks):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name= \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "embeddings = create_embeddings(chunks)\n",
    "print(\"Embeddings created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c0446",
   "metadata": {},
   "source": [
    "Vector Embeddings in Pinecone DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba75348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"Pinecone API KEY\")\n",
    "\n",
    "# Create or connect to an index\n",
    "index_name = \"my-index\"\n",
    "if index_name not in [index.name for index in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # depends on your embedding model\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")  \n",
    "    )\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970849d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created\n"
     ]
    }
   ],
   "source": [
    "def vector_store(chunks, embeddings, index):\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index=index,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    vector_store.add_documents(chunks)\n",
    "    return vector_store\n",
    "vector_store = vector_store(chunks, embeddings, index)\n",
    "print(\"Vector store created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7183aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 1. Initialize Pinecone\n",
    "# ======================\n",
    "pc = Pinecone(api_key=\"PINECONE_API_KEY\")  # ðŸ‘ˆ your env var or string\n",
    "index_name = \"my-index\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# ======================\n",
    "# 2. Load Embeddings\n",
    "# ======================\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Wrap Pinecone index into LangChain VectorStore\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 3. Load LLM (Gemini)\n",
    "# ======================\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=\"Google API Key\", temperature= 0.5  # ðŸ‘ˆ your env var or string\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 4. Build RAG Pipeline\n",
    "# ======================\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86473715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Based on the provided text:\n",
      "\n",
      "**Prognosis** refers to the likely outcome or course of a medical condition or disease. It depends on various factors related to the problem's source and characteristics.\n",
      "\n",
      "Here are examples from the text:\n",
      "\n",
      "*   **Example 1: Pituitary Adenomas**\n",
      "    When pituitary adenomas are identified as the source of increased ACTH leading to cortisol excess, the prognosis is that \"about 80% of patients are cured by surgery.\" This indicates a generally good prognosis for this specific condition when treated surgically.\n",
      "\n",
      "*   **Example 2: Cortisol Excess due to Other Cancer**\n",
      "    If cortisol excess is due to some other form of cancer, \"the prognosis depends on the type of cancer and the extent of its spread.\" This means the likely outcome is variable and determined by how aggressive the cancer is and how far it has advanced.\n",
      "\n",
      "Sources:\n",
      "- {'author': '', 'creationdate': '2017-05-01T10:37:35-07:00', 'creator': '', 'keywords': '', 'moddate': '2017-05-01T10:37:35-07:00', 'page': 391.0, 'page_label': '392', 'producer': 'GPL Ghostscript 9.10', 'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'subject': '', 'title': '', 'total_pages': 759.0}\n",
      "- {'author': '', 'creationdate': '2017-05-01T10:37:35-07:00', 'creator': '', 'keywords': '', 'moddate': '2017-05-01T10:37:35-07:00', 'page': 391.0, 'page_label': '392', 'producer': 'GPL Ghostscript 9.10', 'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'subject': '', 'title': '', 'total_pages': 759.0}\n",
      "- {'author': '', 'creationdate': '2017-05-01T10:37:35-07:00', 'creator': '', 'keywords': '', 'moddate': '2017-05-01T10:37:35-07:00', 'page': 391.0, 'page_label': '392', 'producer': 'GPL Ghostscript 9.10', 'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'subject': '', 'title': '', 'total_pages': 759.0}\n",
      "- {'author': '', 'creationdate': '2017-05-01T10:37:35-07:00', 'creator': '', 'keywords': '', 'moddate': '2017-05-01T10:37:35-07:00', 'page': 391.0, 'page_label': '392', 'producer': 'GPL Ghostscript 9.10', 'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'subject': '', 'title': '', 'total_pages': 759.0}\n",
      "- {'author': '', 'creationdate': '2017-05-01T10:37:35-07:00', 'creator': '', 'keywords': '', 'moddate': '2017-05-01T10:37:35-07:00', 'page': 361.0, 'page_label': '362', 'producer': 'GPL Ghostscript 9.10', 'source': 'data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'subject': '', 'title': '', 'total_pages': 759.0}\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# 5. Ask a Question\n",
    "# ======================\n",
    "query = \"What is Prognosis, explain it with examples \"\n",
    "result = qa_chain.invoke(query)\n",
    "\n",
    "print(\"\\nAnswer:\", result[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"-\", doc.metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector_db_med",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
